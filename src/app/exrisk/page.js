import React from 'react';
import styles from './Exrisk.module.css'
import Footer from '../components/Footer/Footer';

function Exrisk() {
  return (
    <>
    <main className={styles.container}>
        <div className={styles.box}>
        <h3 className={styles.preface}>Thought Experiment: '$99 Enlightenment'</h3>
      <p className={styles.content}>
      Given the vanity of the most popularly imagined enhancements - chiseled features, x-ray vision, super speed etc. - it’s not unsurprising that many find the notion utterly stupid, a symptom of the deep-ceded inferiority complex that seems to have indelibly marked the human mind. Although a more charitable interpretation of things would attribute this yearning for improvement to the loftiness of the human spirit, Schopenhauer’s “will-to-life”, or, if one is so inclined, perhaps the great creative/evolutionary impulse of the cosmos, it’s clear that a non-insignificant source of our desire for enhancement is indeed our own psychopathology. Sure, we want to be “better”, in part, because our powers of reason suggest it would be a good idea. However, we are at least equally motivated - and arguably far more so - by our own dissatisfaction with ourselves, by the sometimes all-too-painful fact of our inadequacy. Many opponents of enhancement, I believe, are acting - whether knowingly or not - in response to this most human issue. This is no way to Be, they warn us. Making ourselves better is not the answer. Neither bigger biceps nor brains will fill the hole in our hearts. Instead, we must learn to love ourselves - for who and what we are. Thus, on some level, arguments against enhancement can be seen as fundamentally psychological in nature, based on an awareness of the reality of human self-loathing and grounded in an understanding that true well-being comes from within, not without. 
      <br></br><br></br>
While this concern is attached to what we may refer to as “superficial” enhancements, it doesn’t seem nearly as relevant to enhancements aimed at preventing the collapse of the human species. Psychologically, there seems to be an entirely different complex behind the desire for positive enhancement - the desire to be “better” - and negative enhancement - the desire to prevent our collective extinction. Where the former is driven by self-loathing, perhaps the latter is driven by the primal fear of death - an individual fear we all hold and then rationalise/project onto the population writ large. While the psycho-physics behind both of these desires are unhealthy - though perfectly natural - they elicit different kinds of intellectual response. Though it’s relatively easy to level an argument against positive enhancement, it’s far harder - even just intuitively - to develop strong arguments against ensuring our continued existence long into the future. Enhancing ourselves so that we can run a little faster or think a little quicker is one thing - superficial child’s play - enhancing ourselves so that we save the future strikes one as something very different - among the most noble and legitimate concerns one could possibly have. 
<br></br><br></br>
For those who haven’t thought much about existential risk and the moral imperative to do everything we can to safeguard against it, just consider this: if we play our cards right, the overwhelming majority of human lives are yet to exist. Should we keep this thing going for a good while, it’s entirely possible that hundreds of billions - maybe even trillions! - of humans will eventually come to have the gift of life. So long as they are lives worth living, that would be hugely Good - morally. If, however, something was to wipe us out, that would mean all those lives would never come to pass; that is, never experience the thrill of a first kiss, the bliss of a scorching sunset, the pure joy of surfing, or the base pleasure of good sex. And so it is that the most important thing we can do, in the present, is to ensure our presence in the future. The greatest Good we can do is to extend the horizon of human existence. 
<br></br><br></br>
Almost every human enhancement can be framed in terms of managing ex-risk. One of the greatest threats to our existence is, among other things, our stupidity. Not only would human superintelligence be a major vibe (at least one presumes), it could also help us solve the problems that could likely wipe us out, whether that be runaway climate change or an earth-ending asteroid impact. Similarly, just as an enhanced immune system might be the key to infinite longevity, it may also be the key to safeguarding against the threat of a genuinely catastrophic pandemic in the future. 
<br></br><br></br>
Ironically, as is a recurring theme in the enhancement debate, the strongest argument against enhancement - avoiding the extinction of our species - becomes the strongest argument for enhancement. But again, as with the rest of this whole thing, the difficulty is in not knowing how things will actually play out, in our not having a crystal ball that affords perfect omniscience. In principle, enhancement is an extraordinary moral imperative. But in practice? Who knows. It’s all a roll of the dice.   
<br></br><br></br>


      </p>
      </div>
    </main>
    <Footer nextTitle="What To Do?" nextPage="/whattodo"/>
    </>
  );
}

export default Exrisk;
